{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random \n",
    "from utils import load_image\n",
    "\n",
    "#from PIL import Image\n",
    "#from .utils import dense_to_one_hot\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_images(path):\n",
    "    \n",
    "    \n",
    "    \"\"\"Reads directory of images in tensorflow\n",
    "    Args:\n",
    "    path:\n",
    "    is_directory:\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for dirs in os.walk(path):\n",
    "        for filename in dirs:\n",
    "            images.append(filename)\n",
    "#    files_path = glob.glob(os.path.join(path, '*.[jJ][pP][eE][gG]'))\n",
    "#    reader = tf.WholeFileReader()\n",
    "#    images = []\n",
    "#    for dir in path:\n",
    "#        for image in dir:\n",
    "#            images.append(image)\n",
    "        \n",
    "    \n",
    "#    if len(images) > 0:\n",
    "#        jpeg_file_queue = tf.train.string_input_producer(images)\n",
    "\n",
    "#        jkey, jvalue = reader.read(jpeg_file_queue)\n",
    "#        j_img = tf.image.decode_jpeg(jvalue)\n",
    "    \n",
    "    return images\n",
    "\n",
    "#def get_images(path,img_shape):\n",
    "#    image_list = read_raw_images(path)\n",
    "#    images= []\n",
    "#    labels = []\n",
    "#    for item in image_list:\n",
    "#        image,label = read_and_decode(item,img_shape)\n",
    "#        images.append(image)\n",
    "#        labels.append(label)\n",
    "#        \n",
    "#    return images,labels\n",
    "        \n",
    "\n",
    "def read_and_decode(path, imshape, normalize=False, flatten=True):\n",
    "    \n",
    "    \"\"\"Reads\n",
    "    Args:\n",
    "    filename_queue:\n",
    "    imshape:\n",
    "    normalize:\n",
    "    flatten:\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    filename_queue = read_raw_images(path)\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(\n",
    "            serialized_example,\n",
    "            features={\n",
    "                    'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "                    'label': tf.FixedLenFeature([], tf.int64)\n",
    "                    })\n",
    "    \n",
    "      # Convert from a scalar string tensor (whose single string has\n",
    "      # length mnist.IMAGE_PIXELS) to a uint8 tensor with shape\n",
    "      # [mnist.IMAGE_PIXELS].\n",
    "    image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "    \n",
    "    if flatten:\n",
    "        num_elements = 1\n",
    "        for i in imshape: num_elements = num_elements * i\n",
    "        print(num_elements)\n",
    "        image = tf.reshape(image, [num_elements])\n",
    "        image.set_shape(num_elements)\n",
    "    else:\n",
    "        image = tf.reshape(image, imshape)\n",
    "        image.set_shape(imshape)\n",
    "    \n",
    "    if normalize:\n",
    "        # Convert from [0, 255] -> [-0.5, 0.5] floats.\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image = tf.cast(image, tf.float32) * (1. / 255) - 0.5\n",
    "    \n",
    "      # Convert label from a scalar uint8 tensor to an int32 scalar.\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "def read_images(path,n_samples):\n",
    "    \"\"\"\n",
    "    path:\n",
    "    imshape:\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    dir_list = os.listdir(path)\n",
    "    index = [random.randint(0,len(dir_list)) for i in range(n_samples)]\n",
    "    #print(index)\n",
    "    for i in index:\n",
    "        dirnames = dir_list[i]\n",
    "        #print(dirnames)\n",
    "        file_list = os.listdir(os.path.join(path,dirnames))\n",
    "        file_index = random.sample(range(0,len(file_list)),1)\n",
    "        file = file_list[file_index[0]]\n",
    "        file_path = os.path.join(path,dirnames,file)\n",
    "        #print(file_path)\n",
    "        img = load_image(file_path)\n",
    "        images.append(img)\n",
    "        print(\"size of image\",img.shape)\n",
    "    images = np.array(images)\n",
    "    return images,index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n",
      "size of image (299, 299, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (299,299,3) into shape (299,299)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-3e7bbad680ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/data3/ILSVRC2012/train/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-f91f2c5587cb>\u001b[0m in \u001b[0;36mread_images\u001b[0;34m(path, n_samples)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"size of image\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (299,299,3) into shape (299,299)"
     ]
    }
   ],
   "source": [
    "images,labels = read_images(\"/data3/ILSVRC2012/train/\",100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "print(images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.ops.data_flow_ops.FIFOQueue object at 0x7f5999892e80>\n"
     ]
    }
   ],
   "source": [
    "#all_images = read_images(\"/data3/ILSVRC2012/train/\")\n",
    "all_images_dir = read_raw_images(\"/data3/ILSVRC2012/train/\")\n",
    "print(all_images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of images: <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "type of labels:  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "shape of images (100000, 299, 299, 3)\n",
      "shape of image: (299, 299, 3)\n",
      "shape of labels : ()\n",
      "dims of images: 100000\n"
     ]
    }
   ],
   "source": [
    "print(\"type of images:\",type(images))\n",
    "print(\"type of labels: \",type(labels))\n",
    "print(\"shape of images\", images.get_shape())\n",
    "print(\"shape of image:\", images[0].get_shape())\n",
    "print(\"shape of labels :\",labels.get_shape())\n",
    "print(\"dims of images:\",images.get_shape()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sess = tf.InteractiveSession()\n",
    "#images = images.eval()\n",
    "#print(\"type of images\",type(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_labels = pd.read_csv(\"/data3/ILSVRC2012/train.txt\",sep=\" \",header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = all_labels[labels.columns[1]][:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = random.sample(range(0,len(labels)),100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(100000), Dimension(299), Dimension(299), Dimension(3)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = [all_images[i] for i in index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = np.asarray(labels[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "(299, 299, 3)\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(images))\n",
    "print(images[0].get_shape())\n",
    "#print(type(labels))\n",
    "#print(\"shape of labels\",labels.shape)\n",
    "print(labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "images = [i.eval() for i in images]\n",
    "images = images.eval()\n",
    "print(\"type of images\",type(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
